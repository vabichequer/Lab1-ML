{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees - Synthetic dataset\n",
    "\n",
    "First we import the libraries we will need. In addition we will use the first code cell to activate the *inline* mode for the graphics generated by *matplotlib*. We also initialize the seed of the random generator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "#np.random.seed(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a synthetic classification problem. The goal is to undestand the main concepts with this problem, after this we will analyze real databases. We will use the \"make_blobs\" function, which generates data from a specified number of blobs. The centers of the blobs are randomly chosen by this function.\n",
    "\n",
    "The parameters we can play with are commented here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nblobs_class0 = 3 # number of blobs\n",
    "Nblobs_class1 = 3\n",
    "nsamples_class0 = 300 # number of points to be generated in class 0\n",
    "nsamples_class1 = 300 # number of points to be generated in class 1\n",
    "nattributes = 2\n",
    "blob_width = 5\n",
    "\n",
    "class_names = ['class 0', 'class 1']\n",
    "attributes_names = ['attribute 0', 'attribute 1']\n",
    "\n",
    "X_class0, _ = make_blobs(random_state = 21,# changing this parameter will lead to different points\n",
    "                         n_samples = nsamples_class0,\n",
    "                         n_features = nattributes,\n",
    "                         centers = Nblobs_class0, # number of blobs (clouds)\n",
    "                         cluster_std = blob_width)\n",
    "\n",
    "X_class1, _ = make_blobs(random_state = 23,# changing this parameter will lead to different points\n",
    "                         n_samples = nsamples_class1,\n",
    "                         n_features = nattributes,\n",
    "                         centers = Nblobs_class1,  # number of blobs (clouds)\n",
    "                         cluster_std = blob_width)\n",
    "\n",
    "X = np.vstack((X_class0, X_class1))\n",
    "y = np.zeros(nsamples_class0 + nsamples_class1)\n",
    "y[nsamples_class0:] = 1\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(X[y==0,0], X[y==0,1], color = 'r', label=class_names[0])\n",
    "plt.scatter(X[y==1,0], X[y==1,1], color = 'b', label=class_names[1])\n",
    "plt.grid()\n",
    "plt.xlabel(attributes_names[0])\n",
    "plt.ylabel(attributes_names[1])\n",
    "plt.title('synthetic data for classification')\n",
    "plt.legend(loc=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train a <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\">\n",
    "DecisionTreeClassifier</a>. The most important arguments for DecisionTreeClassifier builder are the following: \n",
    "\n",
    "- **criterion:** criterion for splitting the tree nodes. It can be 'gini' or 'entropy' (this last is equivalent to information gain).\n",
    "\n",
    "- **max_depth:** maximum depth of the decision tree.\n",
    "\n",
    "The examples reaching a tree node are used to compute statistics related\n",
    "to estimate the quality of subsequent splittings at that node. The examples\n",
    "are also used to compute statistics related to the class to be predicted\n",
    "in case no further splittings are made. This number should be large enough\n",
    "to ensure these statistics quality.\n",
    "Thus requirements about the minimum amount of examples are needed:\n",
    "\n",
    "- **min_samples_split:** minimum number of examples in a tree node required to be splitted.\n",
    "\n",
    "- **min_samples_leaf:** minimum number of examples in a classification node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we make a training set/test set partition of the database in order to properly validate the model. This allows to measure the predictive quality of the model by means of the scoring and the confusion matrix.\n",
    "\n",
    "Try different parameters and respond to the questions made at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# training /test split\n",
    "testsize = 0.3 # in the [0,1] range. 1: 100%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testsize, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the constructed tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"tree.b\", 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "    rules = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell is used to visualize the constructed decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive quality of the model\n",
    "\n",
    "print(\"Score training = %f\" % (clf.score(X_train, y_train)))\n",
    "print(\"Score test = %f\" % (clf.score(X_test, y_test)))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"\\nConfusion matrix in test:\\n\")\n",
    "print(confusion_matrix(y_test, clf.predict(X_test))) # row: real class; column: predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "from libreria_aux_arboles import tree_to_code, tree_to_pseudo\n",
    "tree_to_code(clf, attributes_names)\n",
    "\n",
    "#Source( export_graphviz(clf, out_file=None,\n",
    "#                        feature_names=attributes_names,\n",
    "#                        class_names=class_names,\n",
    "#                        filled=True, rounded=True,\n",
    "#                        special_characters=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same rules but ordered by probability of class\n",
    "target_class = 'class 1'\n",
    "rules.sort(key=lambda e: e[1][class_names.index(target_class)][2], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
